{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eduardo6446/BIMMO_IA/blob/main/BIMMO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instalamos e importamos las librer√≠as necesarias.\n",
        "# Pandas para manejar datos, Sklearn para procesarlos y TensorFlow para la IA.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import joblib # Para guardar los codificadores (LabelEncoders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ùå Error al cargar datos: Expected object or value\n",
            "Aseg√∫rate de que el archivo existe y es un JSONL v√°lido.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3798110820.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
            "  df = pd.read_json(archivo_datos, lines=True)\n"
          ]
        }
      ],
      "source": [
        "# Cargamos el archivo JSONL que generaste con el script anterior.\n",
        "# Aseg√∫rate de haber subido 'datos_entrenamiento_fase2.jsonl' a Colab.\n",
        "\n",
        "archivo_datos = 'datos_entrenamiento_fase2.jsonl'\n",
        "\n",
        "try:\n",
        "    # lines=True es vital para leer JSONL\n",
        "    df = pd.read_json(archivo_datos, lines=True)\n",
        "    print(\"‚úÖ Datos cargados exitosamente.\")\n",
        "    print(f\"Total de registros: {len(df)}\")\n",
        "    print(\"\\nVista previa de los datos:\")\n",
        "    print(df[['modelo_id', 'componente_id', 'km_realizado_usuario', 'condicion_reportada']].head())\n",
        "except ValueError as e:\n",
        "    print(f\"‚ùå Error al cargar datos: {e}\")\n",
        "    print(\"Aseg√∫rate de que el archivo existe y es un JSONL v√°lido.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# La IA no entiende texto (ej: \"Bajaj_Pulsar_NS200\"), solo n√∫meros.\n",
        "# Aqu√≠ convertimos todas las palabras a n√∫meros usando LabelEncoders.\n",
        "\n",
        "# 1. Crear codificadores para columnas de texto\n",
        "le_modelo = LabelEncoder()\n",
        "le_componente = LabelEncoder()\n",
        "le_condicion = LabelEncoder() # Este es nuestro objetivo (Target)\n",
        "\n",
        "# 2. Ajustar y transformar los datos\n",
        "df['modelo_encoded'] = le_modelo.fit_transform(df['modelo_id'])\n",
        "df['componente_encoded'] = le_componente.fit_transform(df['componente_id'])\n",
        "df['condicion_encoded'] = le_condicion.fit_transform(df['condicion_reportada'])\n",
        "\n",
        "# 3. Normalizar el kilometraje (Escalarlo para que est√© entre -1 y 1 aprox)\n",
        "# Esto ayuda a que la red neuronal aprenda m√°s r√°pido.\n",
        "scaler_km = StandardScaler()\n",
        "# reshape(-1, 1) es necesario porque scaler espera una matriz 2D\n",
        "df['km_scaled'] = scaler_km.fit_transform(df['km_realizado_usuario'].values.reshape(-1, 1))\n",
        "\n",
        "print(\"‚úÖ Datos procesados.\")\n",
        "print(\"Ejemplo de mapeo de condiciones (Target):\")\n",
        "for i, clase in enumerate(le_condicion.classes_):\n",
        "    print(f\"  {i} -> {clase}\")\n",
        "\n",
        "# Guardamos los encoders para usarlos luego en la app\n",
        "joblib.dump(le_modelo, 'encoder_modelo.pkl')\n",
        "joblib.dump(le_componente, 'encoder_componente.pkl')\n",
        "joblib.dump(le_condicion, 'encoder_condicion.pkl')\n",
        "joblib.dump(scaler_km, 'scaler_km.pkl')\n",
        "print(\"\\nüíæ Encoders guardados (los necesitar√°s para hacer predicciones reales).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separamos las \"Entradas\" (X) de la \"Salida deseada\" (y).\n",
        "# Tambi√©n dividimos en datos de Entrenamiento (80%) y Prueba (20%).\n",
        "\n",
        "# Entradas: Modelo (num√©rico), Componente (num√©rico), KM (escalado)\n",
        "X = df[['modelo_encoded', 'componente_encoded', 'km_scaled']]\n",
        "\n",
        "# Salida: Condici√≥n (num√©rico)\n",
        "y = df['condicion_encoded']\n",
        "\n",
        "# Divisi√≥n\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Datos de entrenamiento: {X_train.shape}\")\n",
        "print(f\"Datos de prueba: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dise√±amos la arquitectura de la red neuronal con TensorFlow/Keras.\n",
        "\n",
        "num_clases = len(le_condicion.classes_)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Capa de entrada (3 caracter√≠sticas: modelo, componente, km)\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(3,)),\n",
        "    \n",
        "    # Capas ocultas (donde ocurre la \"magia\" del aprendizaje)\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2), # Apaga neuronas al azar para evitar memorizaci√≥n (overfitting)\n",
        "    \n",
        "    # Capa de salida\n",
        "    # Softmax se usa para clasificaci√≥n m√∫ltiple (nos da % de probabilidad para cada estado)\n",
        "    tf.keras.layers.Dense(num_clases, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilamos el modelo\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy', # 'Sparse' porque 'y' son enteros (0, 1, 2...), no one-hot vectors\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ¬°Aqu√≠ es donde la IA aprende!\n",
        "# Epochs = Cu√°ntas veces revisar√° todos los datos.\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=20,           # Puedes aumentar esto si ves que sigue mejorando\n",
        "    batch_size=32,       # Procesa 32 registros a la vez\n",
        "    validation_data=(X_test, y_test),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Entrenamiento finalizado.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualicemos qu√© tan bien aprendi√≥.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Gr√°fica de Precisi√≥n (Accuracy)\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Entrenamiento')\n",
        "plt.plot(history.history['val_accuracy'], label='Validaci√≥n (Prueba)')\n",
        "plt.title('Precisi√≥n del Modelo')\n",
        "plt.xlabel('√âpoca')\n",
        "plt.ylabel('Precisi√≥n')\n",
        "plt.legend()\n",
        "\n",
        "# Gr√°fica de P√©rdida (Loss)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Entrenamiento')\n",
        "plt.plot(history.history['val_loss'], label='Validaci√≥n (Prueba)')\n",
        "plt.title('P√©rdida (Error)')\n",
        "plt.xlabel('√âpoca')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Probemos el modelo con un caso hipot√©tico manual para ver si tiene sentido.\n",
        "\n",
        "def predecir_estado(modelo_nombre, componente_nombre, km_usuario):\n",
        "    try:\n",
        "        # 1. Convertir entradas al formato que entiende la IA\n",
        "        mod_enc = le_modelo.transform([modelo_nombre])[0]\n",
        "        comp_enc = le_componente.transform([componente_nombre])[0]\n",
        "        km_scl = scaler_km.transform([[km_usuario]])[0][0]\n",
        "        \n",
        "        # 2. Predecir\n",
        "        prediccion = model.predict([[mod_enc, comp_enc, km_scl]], verbose=0)\n",
        "        \n",
        "        # 3. Interpretar resultado\n",
        "        clase_ganadora = np.argmax(prediccion)\n",
        "        estado_texto = le_condicion.inverse_transform([clase_ganadora])[0]\n",
        "        confianza = np.max(prediccion) * 100\n",
        "        \n",
        "        print(f\"\\n--- Predicci√≥n para {modelo_nombre} ({componente_nombre}) a los {km_usuario} km ---\")\n",
        "        print(f\"Estado Predicho: {estado_texto.upper()}\")\n",
        "        print(f\"Confianza: {confianza:.2f}%\")\n",
        "        print(\"Probabilidades por estado:\")\n",
        "        for i, prob in enumerate(prediccion[0]):\n",
        "            estado = le_condicion.inverse_transform([i])[0]\n",
        "            print(f\"  - {estado}: {prob*100:.1f}%\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"Error en predicci√≥n (quiz√°s el modelo/componente no existe en los datos): {e}\")\n",
        "\n",
        "# ¬°C√ÅMBIAME! Prueba con valores aqu√≠\n",
        "# Ejemplo: Buj√≠as de una Pulsar NS200 a los 12,000 km (Manual dice cambio a 10,000)\n",
        "# Deber√≠a predecir desgaste alto o muy desgastado.\n",
        "predecir_estado(\"Bajaj_Pulsar_NS200\", \"bujias\", 12000)\n",
        "\n",
        "# Ejemplo: Aceite a los 100 km (Reci√©n cambiado)\n",
        "predecir_estado(\"Bajaj_Pulsar_NS200\", \"aceite_motor\", 100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exportamos el modelo en formato .h5 (est√°ndar Keras) o SavedModel\n",
        "# Este archivo es el que luego cargar√≠amos en el servidor Flask para la Fase 3 real.\n",
        "\n",
        "model.save(\"modelo_mantenimiento_v1.h5\")\n",
        "print(\"‚úÖ Modelo guardado como 'modelo_mantenimiento_v1.h5'\")\n",
        "\n",
        "# Si quieres descargarlo a tu PC desde Colab:\n",
        "from google.colab import files\n",
        "files.download(\"modelo_mantenimiento_v1.h5\")\n",
        "# Tambi√©n descarga los encoders, son indispensables\n",
        "files.download(\"encoder_modelo.pkl\")\n",
        "files.download(\"encoder_componente.pkl\")\n",
        "files.download(\"encoder_condicion.pkl\")\n",
        "files.download(\"scaler_km.pkl\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPtT7oz0BDYx8/xQnCzw5P2",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
